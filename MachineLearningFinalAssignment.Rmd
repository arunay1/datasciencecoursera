---
title: "Machine Learning Final Assignment"
author: "Arunay Kumar"
date: "29 May 2016"
---
## Background
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self-movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

__Data__:

* [Training Data for the assignment is available here:](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv) 
* [Test Data for the assignment is available here:](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)


## References:
Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements. Proceedings of 21st Brazilian Symposium on Artificial Intelligence. Advances in Artificial Intelligence - SBIA 2012. In: Lecture Notes in Computer Science. , pp. 52-61. Curitiba, PR: Springer Berlin / Heidelberg, 2012. ISBN 978-3-642-34458-9. DOI: 10.1007/978-3-642-34459-6_6

* [Read more:](http://groupware.les.inf.puc-rio.br/har#ixzz48MdnjbXS)

### Execution Environment

* Training and Testing data is downloaded for the assignment under the following directory

I am using my own working directory please define your own working directory for code to execute

```{r setup, cache = F, echo = TRUE, message = F, warning = F, tidy = F}

library(rattle)
library(randomForest)
library(caret)
library(rpart)
library(rpart.plot)

set.seed(65432)

wd<-"f:/DataScience/Coursera-DataScienceSpecialization/08_PracticalMachineLearning/00assignment/"
setwd(wd)

```

* Loading Training and Testing Data for Analysis

```{r, echo=TRUE,eval=TRUE}
training <- read.csv(paste(wd,"pml-training.csv",sep=""))
testing  <- read.csv(paste(wd,"pml-testing.csv",sep=""))
```

* Preprocessing

Step One, we see the data for obvious errors and remove the glaring deviations

```{r, echo=TRUE,eval=FALSE}
str(training)
```

We observe training set variables contains number of factor variables, besides this, number of variables have value "#DIV/0!", We remove all variables which have Near Zero Variaance or are NA.

```{r ,dependson="loadPackage",cache=TRUE,fig.height=3.5,fig.width=3.5,echo=TRUE,eval=TRUE}

# remove variables with Nearly Zero Variance
removeVars <- nearZeroVar(training)
training <- training[, -removeVars]
testing  <- testing[, -removeVars]

```

After Loading training Set We divide training Set into Test and Train Set in ratio of 70% and 30%

```{r, echo=TRUE,eval=TRUE}

inTrain  <- createDataPartition(training$classe, p=0.7, list=FALSE)
TrainSet <- training[inTrain, ]
TestSet  <- training[-inTrain, ]
dim(TrainSet)

```

In addition to this we also remove variables which are all NULL

```{r, echo=TRUE,eval=FALSE}
# remove variables that are mostly NA
allNA    <- sapply(TrainSet, function(x) mean(is.na(x))) > 0.95
TrainSet <- TrainSet[,allNA==FALSE]
TestSet  <- TestSet[, allNA==FALSE]
dim(TrainSet)
```

In Training Data Set Variables X, user_name, raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp varaibles are not predictor variables therefore we ignore them from out analysis


```{r, echo=TRUE,eval=TRUE,warning=FALSE}
# remove variables which are not predictor Variables 
TrainSet <- TrainSet[, -(1:5)]
TestSet  <- TestSet[, -(1:5)]
dim(TrainSet)

```
Model Building

Both Test set and training set is properly pre processed and is ready for analysis. I will apply 3 models Random Forest, Decision Tree and Boosted Model and select the best on training set to apply to quiz questions

As basic Preprocessing step we standardize all the training set data and preserve it for use on testing Data set

#### a) Random Forest 
```{r, echo=TRUE,eval=TRUE}
set.seed(65432)
controlRF <- trainControl(method="cv", number=3, verboseIter=FALSE)
modelRF  <- train(classe ~ ., data=TrainSet, method="rf", trControl=controlRF)
modelRF$finalModel
```

Prediction on Test Set

```{r, echo=TRUE,eval=TRUE}
predictRF  <- predict(modelRF, newdata=TestSet)
ConfRF     <- confusionMatrix(predictRF, TestSet$classe)
ConfRF

```

#### b) Decision Tree

```{r, echo=TRUE,eval=TRUE}
set.seed(65432)
modelDT <- rpart(classe ~ ., data=TrainSet, method="class")
fancyRpartPlot(modelDT)
````

#### Prediction on Test Set

```{r, echo=TRUE,eval=TRUE}
predictDT <- predict(modelDT, newdata=TestSet, type="class")
confDT <- confusionMatrix(predictDT, TestSet$classe)
confDT
```

#### c) Boosting
```{r, echo=TRUE,eval=TRUE}
set.seed(65432)
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
modelGBM   <- train(classe ~ ., data=TrainSet, method = "gbm", trControl = controlGBM, verbose = FALSE)
modelGBM$finalModel

```
#### Prediction on Test Set
```{r, echo=TRUE,eval=TRUE}
# prediction on Test dataset
predictGBM <- predict(modelGBM, newdata=TestSet)
confGBM <- confusionMatrix(predictGBM, TestSet$classe)
confGBM
```

## Applying the Selected Model to the Test Data

Of the three classification techniques used, given below the accuracy of the three methods 

Random Forest : 0.9976
Decision Tree : 0.7183
GBM           : 0.9874

From the data we infere that Random forest performs optimum and we will use this for out prediction 

```{r, echo=TRUE,eval=TRUE}
predictTesting <- predict(modelRF, newdata=testing)
predictTesting
```

